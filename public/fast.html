<html>
<head>
	<meta content="text/html; charset=UTF-8" http-equiv="content-type">
	<meta name="viewport" content="width=device-width, initial-scale=1" />
	<link rel="stylesheet" type="text/css" href="standard.css" />
<title>Cone - Optimal Performance</title>
</head>
<body>
	<div id="header">
		<div class="column">
		<a href="/">
			<img src="pegicon.png" width="56" height="56" alt="logo">
		</a>
		</div>
		<span id="title">Cone</span>
		<span id="sub">Optimal Performance</span></div>
		<div class="column flow-opposite">
	</div>

	<div class="text">
	<p>When performance matters, it can matter greatly. For example:</p>
	<ul>
	<li>Highly-distributed, high-demand web services need to deliver sub-second responses.</li>
	<li>Artificial intelligence algorithms must correctly analyze complex signals on the fly.</li>
	<li>Media and 3-d games need to deliver high-quality, immersive experiences without pauses or interruptions.</li>
	</ul>
	<p>Such programs often grow complex more quickly than CPUs get faster.
		To win at this performance game, we must get smarter about architecting programs for performance.
		This means taking better advantage of proven performance strategies, such as 
		cache locality, multi-core machines, distributed computing, and more.</p>
	<p>Cone's commitment to optimal performance begins with its use of LLVM to compile all programs directly to 
		highly-optimized native executables for the targeted delivery platform.
		Thus, there is no performance loss that results from interpretation or JIT translation.
		Additionally, Cone's type system is static and aligned with the way CPUs operate on data,
		which eliminates the use of CPU cycles to operate on needlessly complex data structures.</p>
	<p>Cone goes beyond these tablestakes: A top design goal is making it easier for knowledgeable programmers to
		leverage high-performance strategies to improve throughput and reduce latency.</p>
	
	<h2>Memory and Throughput</h2>
	<p><b>Cache locality:</b>
		In modern CPUs, memory is glacially slow, as fetch speeds are roughly 100x slower than L1 cache.
		As a result, cache-friendly approaches to data layout and access can result in significant thoughput gains.
		Like other systems programming languages, Cone facilitates explicit control over the physical
		size, layout and representation of objects in memory, so as to maximize cache locality.
		When data that is processed together can be located together in small packets, operations unfold
		far more quickly.</p>
	<p><b>Region memory management:</b>
		Cone's region approach to memory management enables significant reductions in runtime overhead
		associated with allocating and freeing memory. 
		For example, a program that exclusively uses ref-counting or tracing GC could improve throughput
		by switching some or all of its memory allocations to use of arenas or pools.
		(Throughput for arenas/pools can be up to 10-20x faster than general-purpose memory allocation and free.)
		Further savings could be realized by transitioning most of its region-managed references to borrowed references.</p>
	<p>Region-based memory management doesn't just improve throughput. It can also be used to reduce (or eliminate)
		stop-the-world lag that can negatively impact systems that need to continuously deliver in real-time.</p>
	
	<h2>Thread communications</h2>
	<p>Another source of unnecessary throughput loss can result from not fully leveraging the 
		parallelism and concurrency capabilities supported by many modern devices.
		This can happen when programs do not spread work across all available CPUs,
		block on I/O (rather than scheduling other work while waiting), or when 
		synchronized communications between concurrent work consume too much time.
		Concurrency can be really hard to get right sometimes.</p>
	<p>Cone is designed to make actors, one of the fastest models of concurrency, the easiest to use.
		What are the performance benefits?</p>
	<ul>
	<li>Actors communicate via messages delivered using a FIFO queue. FIFO queues have very low synchronization costs
		as compared to other synchronization methods (e.g., lock permissions and concurrent data structures).
	<li>Because actors share memory, messages can be short, comprised largely of references to existing, accessible objects</li>
	<li>Message references typically use static permissions, whose safety guarantees carry no runtime lock cost.</li>
	<li>Actors built on top of green threads minimize context switching costs, as compared to OS processes or threads.</li>
	</ul>
	
		
		
		
		
	</div>

</body>
</html>
